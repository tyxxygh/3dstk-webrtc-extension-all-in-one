/*
 
 Copyright (c) 2017, Optical Tone Ltd.
 All rights reserved.
 
 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions are met:
 
 1. Redistributions of source code must retain the above copyright notice, this
 list of conditions and the following disclaimer.
 2. Redistributions in binary form must reproduce the above copyright notice,
 this list of conditions and the following disclaimer in the documentation
 and/or other materials provided with the distribution.
 
 THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
 ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
 ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
 ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 
 The views and conclusions contained in the software and documentation are those
 of the authors and should not be interpreted as representing official policies,
 either expressed or implied, of the FreeBSD Project.
 
 */

namespace org
{
  namespace ortc
  {
    /// <summary>
    /// Capabilities is a dictionary containing one or more key-value pairs,
    /// where each key must be a constrainable property, and each value must
    /// be a subset of the set of values allowed for that property. The exact
    /// type of the value expression depends on the type of the property.
    /// The Capabilities dictionary specifies which constrainable properties
    /// that can be applied, as constraints, to the constrainable object. 
    /// </summary>
    [dictionary]
    struct MediaTrackCapabilities
    {
      typedef std::list<bool> BoolList;

      /// <summary>
      /// The width or width range, in pixels. As a capability, the range should span the
      /// video source's pre-set width values with min being the smallest width and max
      /// being the largest width.
      /// </summary>
      [optional]
      LongRange     width;
      /// <summary>
      /// The height or height range, in pixels. As a capability, the range should span
      /// the video source's pre-set height values with min being the smallest height and
      /// max being the largest height.
      /// </summary>
      [optional]
      LongRange     height;
      /// <summary>
      /// The exact aspect ratio (width in pixels divided by height in pixels, represented
      /// as a double rounded to the tenth decimal place) or aspect ratio range.
      /// </summary>
      [optional]
      DoubleRange   aspectRatio;
      /// <summary>
      /// The exact frame rate (frames per second) or frame rate range. If this frame
      /// rate cannot be determined (e.g. the source does not natively provide a frame rate,
      /// or the frame rate cannot be determined from the source stream), then this value
      /// must refer to the User Agent's vsync display rate.
      /// </summary>
      [optional]
      DoubleRange   frameRate;
      /// <summary>
      /// This string (or each string, when a list) should be one of the members of
      /// VideoFacingMode. The members describe the directions that the camera can
      /// face, as seen from the user's perspective. Note that getConstraints may
      /// not return exactly the same string for strings not in this enum. This
      /// preserves the possibility of using a future version of enum for
      /// this property.
      /// </summary>
      StringList    facingMode;
      /// <summary>
      /// The volume or volume range, as a multiplier of the linear audio sample
      /// values. A volume of 0.0 is silence, while a volume of 1.0 is the maximum
      /// supported volume. A volume of 0.5 will result in an approximately 6 dBSPL
      /// change in the sound pressure level from the maximum volume. Note that any
      /// ConstraintSet that specifies values outside of this range of 0 to 1 can
      /// never be satisfied.
      /// </summary>
      [optional]
      DoubleRange   volume;
      /// <summary>
      /// The sample rate in samples per second for the audio data.
      /// </summary>
      [optional]
      LongRange     sampleRate;
      /// <summary>
      /// The linear sample size in bits. This constraint can only be satisfied for
      /// audio devices that produce linear samples.
      /// </summary>
      [optional]
      LongRange     sampleSize;
      /// <summary>
      /// When one or more audio streams is being played in the processes of
      /// various microphones, it is often desirable to attempt to remove the
      /// sound being played from the input signals recorded by the microphones.
      /// This is referred to as echo cancellation. There are cases where it is
      /// not needed and it is desirable to turn it off so that no audio artifacts
      /// are introduced. This allows applications to control this behavior.
      /// </summary>
      BoolList      echoCancellation;
      /// <summary>
      /// The latency or latency range, in seconds. The latency is the time
      /// between start of processing (for instance, when sound occurs in
      /// the real world) to the data being available to the next step in
      /// the process. Low latency is critical for some applications; high
      /// latency may be acceptable for other applications because it helps
      /// with power constraints. The number is expected to be the target
      /// latency of the configuration; the actual latency may show some
      /// variation from that.
      /// </summary>
      [optional]
      DoubleRange   latency;
      /// <summary>
      /// The number of independent channels of sound that the audio data contains,
      /// i.e. the number of audio samples per sample frame.
      /// </summary>
      [optional]
      LongRange     channelCount;

      /// <summary>
      /// The origin-unique identifier for the source of the MediaStreamTrack.
      /// </summary>
      string        deviceId;
      /// <summary>
      /// The browsing session-unique group identifier for the source of the MediaStreamTrack.
      /// </summary>
      string        groupId;

      /// <summary>
      /// Constructs an empty instance of a MediaTrackCapabilities object.
      /// </summary>
      [constructor, default]
      void MediaTrackCapabilities();
      /// <summary>
      /// Constructs an instance of a MediaTrackCapabilities object by cloning object data from an existing object.
      /// </summary>
      [constructor, altname(MediaTrackCapabilitiesClone)]
      void MediaTrackCapabilities(MediaTrackCapabilities source);
      /// <summary>
      /// Constructs an instance of a MediaTrackCapabilities object by extracting object data from a JSON object.
      /// </summary>
      [constructor, default, altname(MediaTrackCapabilitiesWithJson)]
      void MediaTrackCapabilities(Json json);

      /// <summary>
      /// A helper routine to convert the object's data to structured JSON object data.
      /// </summary>
      Json toJson();
      /// <summary>
      /// Return a hash of the data contained within the object.
      /// </summary>
      string hash();
    };

    /// <summary>
    /// Settings is a dictionary containing one or more key-value pairs.
    /// It must contain each key returned in GetCapabilities(). There must be
    /// a single value for each key and the value must be a member of the set
    /// defined for that property by getCapabilities(). The Settings
    /// dictionary contains the actual values that the User Agent has chosen
    /// for the object's constrainable properties. The exact syntax of the
    /// value depends on the type of the property.
    /// </summary>
    [dictionary]
    struct MediaTrackSettings
    {
      /// <summary>
      /// The width or width range, in pixels. As a capability, the range should span the
      /// video source's pre-set width values with min being the smallest width and max
      /// being the largest width.
      /// </summary>
      [optional]
      long     width;
      /// <summary>
      /// The height or height range, in pixels. As a capability, the range should span
      /// the video source's pre-set height values with min being the smallest height and
      /// max being the largest height.
      /// </summary>
      [optional]
      long     height;
      /// <summary>
      /// The exact aspect ratio (width in pixels divided by height in pixels, represented
      /// as a double rounded to the tenth decimal place) or aspect ratio range.
      /// </summary>
      [optional]
      double   aspectRatio;
      /// <summary>
      /// The exact frame rate (frames per second) or frame rate range. If this frame
      /// rate cannot be determined (e.g. the source does not natively provide a frame rate,
      /// or the frame rate cannot be determined from the source stream), then this value
      /// must refer to the User Agent's vsync display rate.
      /// </summary>
      [optional]
      double   frameRate;
      /// <summary>
      /// This string (or each string, when a list) should be one of the members of
      /// VideoFacingMode. The members describe the directions that the camera can
      /// face, as seen from the user's perspective. Note that getConstraints may
      /// not return exactly the same string for strings not in this enum. This
      /// preserves the possibility of using a future version of enum for
      /// this property.
      /// </summary>
      [optional]
      string   facingMode;
      /// <summary>
      /// The volume or volume range, as a multiplier of the linear audio sample
      /// values. A volume of 0.0 is silence, while a volume of 1.0 is the maximum
      /// supported volume. A volume of 0.5 will result in an approximately 6 dBSPL
      /// change in the sound pressure level from the maximum volume. Note that any
      /// ConstraintSet that specifies values outside of this range of 0 to 1 can
      /// never be satisfied.
      /// </summary>
      [optional]
      double   volume;
      /// <summary>
      /// The sample rate in samples per second for the audio data.
      /// </summary>
      [optional]
      long     sampleRate;
      /// <summary>
      /// The linear sample size in bits. This constraint can only be satisfied for
      /// audio devices that produce linear samples.
      /// </summary>
      [optional]
      long     sampleSize;
      /// <summary>
      /// When one or more audio streams is being played in the processes of
      /// various microphones, it is often desirable to attempt to remove the
      /// sound being played from the input signals recorded by the microphones.
      /// This is referred to as echo cancellation. There are cases where it is
      /// not needed and it is desirable to turn it off so that no audio artifacts
      /// are introduced. This allows applications to control this behavior.
      /// </summary>
      [optional]
      bool     echoCancellation;
      /// <summary>
      /// The latency or latency range, in seconds. The latency is the time
      /// between start of processing (for instance, when sound occurs in
      /// the real world) to the data being available to the next step in
      /// the process. Low latency is critical for some applications; high
      /// latency may be acceptable for other applications because it helps
      /// with power constraints. The number is expected to be the target
      /// latency of the configuration; the actual latency may show some
      /// variation from that.
      /// </summary>
      [optional]
      double   latency;
      /// <summary>
      /// The number of independent channels of sound that the audio data contains,
      /// i.e. the number of audio samples per sample frame.
      /// </summary>
      [optional]
      long     channelCount;
      /// <summary>
      /// The origin-unique identifier for the source of the MediaStreamTrack.
      /// </summary>

      [optional]
      string   deviceId;
      /// <summary>
      /// The browsing session-unique group identifier for the source of the MediaStreamTrack.
      /// </summary>
      [optional]
      string   groupId;

      /// <summary>
      /// Constructs an empty MediaTrackSettings object instance.
      /// </summary>
      [constructor, default]
      void MediaTrackSettings();
      /// <summary>
      /// Constructs an MediaTrackSettings object instance by cloning object data from an existing object.
      /// </summary>
      [constructor, altname(MediaTrackSettingsClone)]
      void MediaTrackSettings(MediaTrackSettings source);
      /// <summary>
      /// Constructs an MediaTrackSettings object instance by extracting object data from a JSON object.
      /// </summary>
      [constructor, default, altname(MediaTrackSettingsWithJson)]
      void MediaTrackSettings(Json json);

      /// <summary>
      /// A helper routine to convert the object's data to structured JSON object data.
      /// </summary>
      Json toJson();
      /// <summary>
      /// Return a hash of the data contained within the object.
      /// </summary>
      string hash();
    };

    /// <summary>
    /// Each member of a ConstraintSet corresponds to a constrainable property
    /// and specifies a subset of the property's legal Capability values.
    /// Applying a ConstraintSet instructs the User Agent to restrict the
    /// settings of the corresponding constrainable properties to the
    /// specified values or ranges of values. A given property may occur both
    /// in the basic Constraints set and in the advanced ConstraintSets list,
    /// and may occur at most once in each ConstraintSet in the advanced list.
    /// </summary>
    [dictionary]
    struct MediaTrackConstraintSet
    {
      /// <summary>
      /// The width or width range, in pixels. As a capability, the range
      /// should span the video source's pre-set width values with min being
      /// the smallest width and max being the largest width.
      /// </summary>
      ConstrainLong     width;
      /// <summary>
      /// The height or height range, in pixels. As a capability, the range
      /// should span the video source's pre-set height values with min being
      /// the smallest height and max being the largest height.
      /// </summary>
      ConstrainLong     height;
      /// <summary>
      /// The exact aspect ratio (width in pixels divided by height in pixels,
      /// represented as a double rounded to the tenth decimal place) or
      /// aspect ratio range.
      /// </summary>
      ConstrainDouble   aspectRatio;
      /// <summary>
      /// The exact frame rate (frames per second) or frame rate range. If
      /// this frame rate cannot be determined (e.g. the source does not
      /// natively provide a frame rate, or the frame rate cannot be
      /// determined from the source stream), then this value must refer to
      /// the User Agent's vsync display rate.
      /// </summary>
      ConstrainDouble   frameRate;
      /// <summary>
      /// This string (or each string, when a list) should be one of the
      /// members of VideoFacingModeEnum. The members describe the directions
      /// that the camera can face, as seen from the user's perspective. Note
      /// that getConstraints may not return exactly the same string for
      /// strings not in this enum. This preserves the possibility of using a
      /// future version of WebIDL enum for this property.
      /// </summary>
      ConstrainString   facingMode;
      /// <summary>
      /// The volume or volume range, as a multiplier of the linear audio
      /// sample values. A volume of 0.0 is silence, while a volume of 1.0 is
      /// the maximum supported volume. A volume of 0.5 will result in an
      /// approximately 6 dBSPL change in the sound pressure level from the
      /// maximum volume. Note that any ConstraintSet that specifies values
      /// outside of this range of 0 to 1 can never be satisfied.
      /// </summary>
      ConstrainDouble   volume;
      /// <summary>
      /// The sample rate in samples per second for the audio data.
      /// </summary>
      ConstrainLong     sampleRate;
      /// <summary>
      /// The linear sample size in bits. This constraint can only be
      /// satisfied for audio devices that produce linear samples.
      /// </summary>
      ConstrainLong     sampleSize;
      /// <summary>
      /// When one or more audio streams is being played in the processes of
      /// various microphones, it is often desirable to attempt to remove the
      /// sound being played from the input signals recorded by the
      /// microphones. This is referred to as echo cancellation. There are
      /// cases where it is not needed and it is desirable to turn it off so
      /// that no audio artifacts are introduced. This allows applications to
      /// control this behavior.
      /// </summary>
      ConstrainBoolean  echoCancellation;
      /// <summary>
      /// The latency or latency range, in seconds. The latency is the time
      /// between start of processing (for instance, when sound occurs in the
      /// real world) to the data being available to the next step in the
      /// process. Low latency is critical for some applications; high latency
      /// may be acceptable for other applications because it helps with power
      /// constraints. The number is expected to be the target latency of the
      /// configuration; the actual latency may show some variation from that.
      /// </summary>
      ConstrainDouble   latency;
      /// <summary>
      /// The number of independent channels of sound that the audio data
      /// contains, i.e. the number of audio samples per sample frame.
      /// </summary>
      ConstrainLong     channelCount;
      /// <summary>
      /// The origin-unique identifier for the source of the MediaStreamTrack.
      /// The same identifier must be valid between browsing sessions of this
      /// origin, but must also be different for other origins. Some sort of
      /// GUID is recommended for the identifier. Note that the setting of
      /// this property is uniquely determined by the source that is attached
      /// to the MediaStreamTrack. In particular, getCapabilities() will
      /// return only a single value for deviceId. This property can therefore
      /// be used for initial media selection with getUserMedia(). However,
      /// it is not useful for subsequent media control with
      /// applyConstraints(), since any attempt to set a different value will
      /// result in an unsatisfiable ConstraintSet.
      /// </summary>
      ConstrainString   deviceId;
      /// <summary>
      /// The browsing session-unique group identifier for the source of the
      /// MediaStreamTrack. Two devices have the same group identifier if they
      /// belong to the same physical device; for example, the audio input and
      /// output devices representing the speaker and microphone of the same
      /// headset would have the same groupId. Note that the setting of this
      /// property is uniquely determined by the source that is attached to
      /// the MediaStreamTrack. In particular, getCapabilities() will return
      /// only a single value for groupId. Since this property is not stable 
      /// between browsing sessions its usefulness for initial media selection
      /// with getUserMedia() is limited. It is not useful for subsequent
      /// media control with applyConstraints(), since any attempt to set a
      /// different value will result in an unsatisfiable ConstraintSet.
      /// </summary>
      ConstrainString   groupId;

      /// <summary>
      /// Constructs an empty MediaTrackConstraintSet object instance.
      /// </summary>
      [constructor, default]
      void MediaTrackConstraintSet();
      /// <summary>
      /// Constructs an MediaTrackConstraintSet object instance by cloning object data an existing object.
      /// </summary>
      [constructor, altname(MediaTrackConstraintSetClone)]
      void MediaTrackConstraintSet(MediaTrackConstraintSet source);
      /// <summary>
      /// Constructs an MediaTrackConstraintSet object instance by extracting object data from a JSON object.
      /// </summary>
      [constructor, default, altname(MediaTrackConstraintSetWithJson)]
      void MediaTrackConstraintSet(Json json);

      /// <summary>
      /// A helper routine to convert the object's data to structured JSON object data.
      /// </summary>
      Json toJson();
      /// <summary>
      /// Return a hash of the data contained within the object.
      /// </summary>
      string hash();
    };

    /// <summary>
    /// MediaTrackConstraints represents a set of media stream track constraints to be applied to a MediaStreamTrack.
    /// </summary>
    [dictionary]
    struct MediaTrackConstraints : MediaTrackConstraintSet
    {
      typedef std::list<MediaTrackConstraintSet> ConstraintSetList;

      /// <summary>
      /// Gets or sets the advanced list of ConstraintSets that the User Agent
      /// must attempt to satisfy, in order, skipping only those that cannot
      /// be satisfied. The order of these ConstraintSets is significant. In
      /// particular, when they are passed as an argument to applyConstraints,
      /// the User Agent must try to satisfy them in the order that is
      /// specified. Thus if optional ConstraintSets C1 and C2 can be
      /// satisfied individually, but not together, then whichever of C1 and
      /// C2 is first in this list will be satisfied, and the other will not.
      /// The User Agent must attempt to satisfy all optional ConstraintSets
      /// in the list, even if some cannot be satisfied. Thus, in the
      /// preceding example, if optional constraint C3 is specified after C1
      /// and C2, the User Agent will attempt to satisfy C3 even though C2
      /// cannot be satisfied. Note that a given property name may occur only
      /// once in each ConstraintSet but may occur in more than one
      /// ConstraintSet.
      /// </summary>
      ConstraintSetList advanced;

      /// <summary>
      /// Constructs an empty instance of the MediaTrackConstraints object.
      /// </summary>
      [constructor, default]
      void MediaTrackConstraints();
      /// <summary>
      /// Constructs an instance of the MediaTrackConstraints object by cloning object data from an existing object.
      /// </summary>
      [constructor, altname(MediaTrackConstraintsClone)]
      void MediaTrackConstraints(MediaTrackConstraints source);
      /// <summary>
      /// Constructs an instance of the MediaTrackConstraints object by extracting object data from a JSON object.
      /// </summary>
      [constructor, default, altname(MediaTrackConstraintsWithJson)]
      void MediaTrackConstraints(Json json);
    };

    /// <summary>
    /// The MediaStreamConstraints dictionary is used to instruct the User
    /// Agent what sort of MediaStreamTracks to include in the MediaStream
    /// returned by GetUserMedia().
    /// </summary>
    [dictionary]
    struct MediaStreamConstraints
    {
      /// <summary>
      /// If set, it requests that the returned MediaStream contain an audio
      /// track. If a Constraints structure is provided, it further specifies
      /// the nature and settings of the audio Track. If not set, the
      /// MediaStream must not contain an audio Track.
      /// </summary>
      [optional, nullable]
      MediaTrackConstraints audio;
      /// <summary>
      /// If set, it requests that the returned MediaStream contain a video
      /// track. If a Constraints structure is provided, it further specifies
      /// the nature and settings of the video Track. If not set, the
      /// MediaStream must not contain a video Track.
      /// </summary>
      [optional, nullable]
      MediaTrackConstraints video;

      /// <summary>
      /// Constructs an empty instance of the MediaStreamConstraints object.
      /// </summary>
      [constructor, default]
      void MediaStreamConstraints();
      /// <summary>
      /// Constructs an instance of the MediaStreamConstraints object by cloning object data from an existing object.
      /// </summary>
      [constructor, altname(MediaStreamConstraintsClone)]
      void MediaStreamConstraints(MediaStreamConstraints source);
      /// <summary>
      /// Constructs an instance of the MediaStreamConstraints object by extracting object data from a JSON object.
      /// </summary>
      [constructor, default, altname(MediaStreamConstraintsWithJson)]
      void MediaStreamConstraints(Json json);

      /// <summary>
      /// A helper routine to convert the object's data to structured JSON object data.
      /// </summary>
      Json toJson();
      /// <summary>
      /// Return a hash of the data contained within the object.
      /// </summary>
      string hash();
    };

    /// <summary>
    /// The constraint attribute is set to the name of any one of the
    /// constraints that caused the error, if any.
    /// </summary>
    [dictionary]
    struct OverconstrainedError
    {
      /// <summary>
      /// Gets a string representing one of the error type names.
      /// </summary>
      string name;
      /// <summary>
      /// The constraint property name where the error originated.
      /// </summary>
      string constraint;
      /// <summary>
      /// A message describing the error condition for the constraint.
      /// </summary>
      string message;
    };
    typedef PromiseRejectionReason<OverconstrainedError> PromiseRejectionReasonOverconstrainedError;

    /// <summary>
    /// This error event fires for each affected track (when multiple tracks
    /// share the same source) after the User Agent has evaluated the current
    /// constraints against a given source and is not able to configure the
    /// source within the limitations established by the intersection of
    /// imposed constraints.
    ///
    /// Due to being over - constrained, the User Agent must mute each
    /// affected track.
    ///
    /// The affected track(s) will remain muted until the application adjusts
    /// the constraints to accommodate the source's current effective
    /// capabilities.
    /// </summary>
    struct OverconstrainedErrorEvent
    {
      /// <summary>
      /// Gets the OverconstrainedError describing the error associated with
      /// the event (if any).
      /// </summary>
      [getter]
      OverconstrainedError error;
    };

    /// <summary>
    /// MediaSource represents an object holder for a platform specific media source.
    /// </summary>
    [special]
    struct MediaSource
    {
      /// <summary>
      /// Gets or sets the platform specific media source.
      /// </summary>
      [getter, setter]
      zs::Any source;

      /// <summary>
      /// Gets or sets the media track associated to the media source.
      /// </summary>
      [getter]
      zs::Any track;
    };

    /// <summary>
    /// A MediaStreamTrack object represents a media source in the User Agent.
    /// An example source is a device connected to the User Agent. Other
    /// specifications may define sources for MediaStreamTrack that override
    //// the behavior specified here. Several MediaStreamTrack objects can
    //// represent the same media source, e.g., when the user chooses the same
    //// camera in the UI shown by two consecutive calls to getUserMedia() .
    /// </summary>
    interface MediaStreamTrack
    {
      /// <summary>
      /// Gets a unique object instance identifier for this object.
      /// </summary>
      [getter]
      puid objectId;

      /// <summary>
      /// Gets a kind attribute that must return the string "Audio" if this
      /// object represents an audio track or "Video" if this object
      /// represents a video track.
      /// </summary>
      [getter]
      MediaStreamTrackKind kind;

      /// <summary>
      /// Gets a User Agent generated an identifier string.
      /// </summary>
      [getter]
      string id;

      /// <summary>
      /// Gets a unique identifier for the represented device.
      /// </summary>
      [getter]
      string deviceId;

      /// <summary>
      /// Gets the label of the object's corresponding source, if any. If
      /// the corresponding source has or had no label, the attribute must
      /// instead return the empty string..
      /// User Agents may label audio and video sources (e.g., "Internal
      /// microphone" or "External USB Webcam").
      /// </summary>
      [getter]
      string label;

      /// <summary>
      /// Gets or sets the enabled state for the object. On getting, the
      /// attribute must return the value to which it was last set. On
      /// setting, it must be set to the new value.
      /// </summary>
      [getter, setter]
      bool enabled;

      /// <summary>
      /// Gets or sets the muted state of the object.
      /// </summary>
      /// <returns>true if the track is muted, and false otherwise.</returns>
      [getter, setter]
      bool muted;

      /// <summary>
      /// Gets if the track source origin is local or remote.
      /// </summary>
      /// <returns>true if the source origin is remote, otherwise false</returns>
      [getter]
      bool remote;

      /// <summary>
      /// Gets the state of the track.
      /// </summary>
      /// <returns>The value as most recently set by the User Agent.</returns>
      [getter]
      MediaStreamTrackState readyState;

      /// <summary>
      /// Gets or sets a MediaSource capable of being rendered to an output
      /// window based upon the current track.
      /// </summary>
      [getter]
      MediaSource source;

      [constructor, delete]
      void MediaStreamTrack();

      /// <summary>
      /// Clones this MediaStreamTrack.
      /// </summary>
      MediaStreamTrack clone();

      /// When a MediaStreamTrack object's stop() method is invoked, the User Agent must run following steps:
      /// 1. Let track be the current MediaStreamTrack object.
      /// 2. Notify track's source that track is ended.
      ///    A source that is notified of a track ending will be stopped,
      ///    unless other MediaStreamTrack objects depend on it
      /// 3. Set track's readyState attribute to ended.
      void stop();

      /// <summary>
      /// Returns the dictionary of the names of the constrainable propertie
      /// that the object supports.
      MediaTrackCapabilities getCapabilities();
      /// <summary>
      /// Returns the Constraints that were the argument to the most recent
      /// successful call of ApplyConstraints(), maintaining the order in
      /// which they were specified. Note that some of the optional
      /// ConstraintSets returned may not be currently satisfied. To check
      /// which ConstraintSets are currently in effect, the application should
      /// use GetSettings.
      /// </summary>
      MediaTrackConstraints getConstraints();
      /// <summary>
      /// Returns the current settings of all the constrainable properties of
      /// the object, whether they are platform defaults or have been set by
      /// ApplyConstraints(). Note that the actual setting of a property must
      /// be a single value.
      /// </summary>
      MediaTrackSettings getSettings();

      /// <summary>
      /// The User Agent may choose new settings for the constrainable
      /// properties of the object at any time. When it does so it must
      /// attempt to satisfy the current Constraints
      /// </summary>
      zs::Promise applyConstraints(MediaTrackConstraints constraints) throws(InvalidParameters);

      /// <summary>
      /// The MediaStreamTrack object's source is temporarily unable to
      /// provide data.
      /// </summary>
      [event]
      void onMute();

      /// <summary>
      /// The MediaStreamTrack object's source is live again after having been
      /// temporarily unable to provide data.
      /// </summary>
      [event]
      void onUnmute();

      /// <summary>
      /// The MediaStreamTrack object's source will no longer provide any
      /// data, either because the user revoked the permissions, or because
      /// the source device has been ejected, or because the remote peer
      /// permanently stopped sending data.
      /// </summary>
      [event]
      void onEnded();

      /// <summary>
      /// This error event fires for each affected track(when multiple tracks
      /// share the same source) after the User Agent has evaluated the
      /// current constraints against a given source and is not able to
      /// configure the source within the limitations established by the
      /// intersection of imposed constraints.
      ///
      /// Due to being over - constrained, the User Agent must mute each
      /// affected track.
      ///
      /// The affected track(s) will remain muted until the application
      /// adjusts the constraints to accommodate the source's current
      /// effective capabilities.
      /// </summary>
      [event]
      void onOverConstrained(OverconstrainedErrorEvent event);
    };
  }
}
